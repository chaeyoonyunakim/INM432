{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1YCTaqmYYfV"
   },
   "source": [
    "## 0. Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "C1KBaWJJk4Qg"
   },
   "outputs": [],
   "source": [
    "# import basics\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "seed = 20211001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qghbo96ZlCTN",
    "outputId": "6b9059ca-d3d0-408c-ef4f-a66e4a9b8c22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chaey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chaey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\chaey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import nlp relevants\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "set(stopwords.words('english'))\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# for bag-of-words (bow)\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VGJtj4fPlFid"
   },
   "outputs": [],
   "source": [
    "# import scikit-learn tools for modelling and evaluation\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ApUkA-SzlD3c"
   },
   "outputs": [],
   "source": [
    "# import algos\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUs8fZVzZnq2"
   },
   "source": [
    "## 1. Data Loading & Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0khrcFZZqsS"
   },
   "source": [
    "***Tabular representation of the dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "RIiQFE9QrFN2",
    "outputId": "11de827f-e301-4520-a969-1960c3be7ad4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Was Jacqueline Kennedy Onassis a follower of M...</td>\n",
       "      <td>boolean</td>\n",
       "      <td>[boolean]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the name of the opera based on Twelfth...</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Opera, dbo:MusicalWork, dbo:Work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>When did Lena Horne receive the Grammy Award f...</td>\n",
       "      <td>literal</td>\n",
       "      <td>[date]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Do Prince Harry and Prince William have the sa...</td>\n",
       "      <td>boolean</td>\n",
       "      <td>[boolean]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Which is the hierarchical BrainInfo ID of the ...</td>\n",
       "      <td>literal</td>\n",
       "      <td>[string]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40616</th>\n",
       "      <td>50708</td>\n",
       "      <td>what kinds of music is played by season's end</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Genre, dbo:TopicalConcept, dbo:MusicGenre]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40617</th>\n",
       "      <td>50709</td>\n",
       "      <td>which asteroid group is 6753 fursenko a member...</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Album]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40618</th>\n",
       "      <td>50710</td>\n",
       "      <td>What language is azhakiya ravanan filmed in?</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Language]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40619</th>\n",
       "      <td>50712</td>\n",
       "      <td>which position did herby fortunat play in foot...</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Person]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40620</th>\n",
       "      <td>50713</td>\n",
       "      <td>who is a person that was born in sao paulo</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Person, dbo:Artist, dbo:MusicalArtist, db...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37084 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           question  category  \\\n",
       "0          0  Was Jacqueline Kennedy Onassis a follower of M...   boolean   \n",
       "1          1  What is the name of the opera based on Twelfth...  resource   \n",
       "2          2  When did Lena Horne receive the Grammy Award f...   literal   \n",
       "3          3  Do Prince Harry and Prince William have the sa...   boolean   \n",
       "4          5  Which is the hierarchical BrainInfo ID of the ...   literal   \n",
       "...      ...                                                ...       ...   \n",
       "40616  50708      what kinds of music is played by season's end  resource   \n",
       "40617  50709  which asteroid group is 6753 fursenko a member...  resource   \n",
       "40618  50710       What language is azhakiya ravanan filmed in?  resource   \n",
       "40619  50712  which position did herby fortunat play in foot...  resource   \n",
       "40620  50713         who is a person that was born in sao paulo  resource   \n",
       "\n",
       "                                                    type  \n",
       "0                                              [boolean]  \n",
       "1                 [dbo:Opera, dbo:MusicalWork, dbo:Work]  \n",
       "2                                                 [date]  \n",
       "3                                              [boolean]  \n",
       "4                                               [string]  \n",
       "...                                                  ...  \n",
       "40616    [dbo:Genre, dbo:TopicalConcept, dbo:MusicGenre]  \n",
       "40617                                        [dbo:Album]  \n",
       "40618                                     [dbo:Language]  \n",
       "40619                                       [dbo:Person]  \n",
       "40620  [dbo:Person, dbo:Artist, dbo:MusicalArtist, db...  \n",
       "\n",
       "[37084 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "train_data = pd.read_json('C:/Users/chaey/INM713-python-main/smart-2021-dataset-main/smart2021-AT_Answer_Type_Prediction/dbpedia/task1_dbpedia_train.json')\n",
    "test_data = pd.read_json('C:/Users/chaey/INM713-python-main/smart-2021-dataset-main/smart2021-AT_Answer_Type_Prediction/dbpedia/task1_dbpedia_test.json')\n",
    "\n",
    "# drop na in training dataset\n",
    "train_data.dropna(subset=['id', 'question', 'category'], inplace=True)\n",
    "\n",
    "# check the format of tabluar representation\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tc3FaIg_tHHC"
   },
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7LfNufdhaCV"
   },
   "source": [
    "***Extract, Transform, Load (ETL)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Epe56ypal-qk"
   },
   "outputs": [],
   "source": [
    "class ETL:\n",
    "\n",
    "    # split training dataset to exclude validation dataset\n",
    "    # set train:val = 8:2\n",
    "    def split_data(self, data, val_size = 0.2):\n",
    "        df_train, df_test = model_selection.train_test_split(data, test_size = val_size, random_state = seed)\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "    # text normalization - stemming, lemmatization, stopwords\n",
    "    ps = PorterStemmer()\n",
    "    wordnet_lemmatizer = WordNetLemmatizer() \n",
    "    s_words = stopwords.words()\n",
    "\n",
    "    # normalization of question sentences\n",
    "    def _norm_sent(self, sent, rm_stopwords = True, stemming = True, lemmatization = True):\n",
    "        # tokenize - sentence to word\n",
    "        words = word_tokenize(sent)\n",
    "        # take if all characters in the string are alphabets and then decapitalize\n",
    "        sent = [w.lower() for w in words if w.isalpha()] \n",
    "\n",
    "        # remove stopwords\n",
    "        if rm_stopwords:\n",
    "            sent = [w for w in sent if w not in self.s_words]\n",
    "\n",
    "        # apply stemming \n",
    "        if stemming:\n",
    "            sent = [self.ps.stem(w) for w in sent]\n",
    "\n",
    "        # apply lemmatization \n",
    "        if lemmatization:\n",
    "            sent = [self.wordnet_lemmatizer.lemmatize(w) for w in sent]\n",
    "\n",
    "        sent = \" \".join(sent)\n",
    "        return sent  \n",
    "  \n",
    "  # add a new column to show how question parsing has done through normalization above\n",
    "  # for Tabular representation of the dataset\n",
    "    def norm_data(self, data):   \n",
    "        data.loc[:, \"question_processed\"] = data[\"question\"].apply(lambda x: self._norm_sent(x, rm_stopwords = False, lemmatization = True, stemming = False))\n",
    "        return data\n",
    "\n",
    "\n",
    "\n",
    "    # transform a given text into a vector\n",
    "    def __init__(self, path_to_type_maps = None, path_to_vectorizers = None):\n",
    "\n",
    "        # load type maps if requested\n",
    "        self.type_maps = {}\n",
    "        self.inv_type_maps = {}\n",
    "        if path_to_type_maps != None:\n",
    "            paths = [fp for fp in os.listdir(\"./\") if \"type\" in fp]\n",
    "            for fp in paths:\n",
    "                type_name = fp.split(\"_\")[0]\n",
    "                with open(fp, \"r\") as input_file:\n",
    "                    self.type_maps[type_name] = json.load(input_file)\n",
    "                    self.inv_type_maps[type_name] = {}\n",
    "                    for ontology, ind in self.type_maps[type_name].items():\n",
    "                        self.inv_type_maps[type_name][ind] = ontology \n",
    "\n",
    "        # load data vectorizers if requested\n",
    "        if path_to_vectorizers != None:\n",
    "            paths = [fp for fp in os.listdir(\"./\") if \"vectorizer\" in fp]\n",
    "            for fp in paths:\n",
    "                vectorizer_name = fp.split(\"_\")[0]\n",
    "                with open(fp, \"rb\") as input_file:\n",
    "                    if vectorizer_name == \"count\":\n",
    "                        self.count_vectorizer = pickle.load(input_file)\n",
    "                    elif vectorizer_name == \"tfidf\":\n",
    "                        self.tfidf_vectorizer = pickle.load(input_file)\n",
    "                    else:\n",
    "                        NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "    # set default feature_extraction parameters\n",
    "    count_vectorizer = None \n",
    "    inv_count_vectorizer_vocab = None\n",
    "    tfidf_vectorizer = None\n",
    "    inv_tfidf_vectorizer_vocab = None\n",
    "\n",
    "    # vectorization\n",
    "    def bow_fit(self, corpus, type = \"tf\", max_features = 10000, ngram_range = (1,2)):\n",
    "\n",
    "        if type == \"tf\":\n",
    "            self.count_vectorizer = feature_extraction.text.CountVectorizer(max_features = max_features, ngram_range = ngram_range)\n",
    "            self.count_vectorizer.fit(corpus[\"question_processed\"])\n",
    "\n",
    "            # create a reverse mapping for the vocab\n",
    "            self.inv_count_vectorizer_vocab = {}\n",
    "            for label, ind in self.count_vectorizer.vocabulary_.items():\n",
    "                self.inv_count_vectorizer_vocab[ind] = label\n",
    "\n",
    "        elif type == \"tfidf\": \n",
    "            self.tfidf_vectorizer = feature_extraction.text.TfidfVectorizer(max_features = max_features, ngram_range = ngram_range)\n",
    "            self.tfidf_vectorizer.fit(corpus[\"question_processed\"])\n",
    "\n",
    "            # create a reverse mapping for the vocab\n",
    "            self.inv_tfidf_vectorizer_vocab = {}\n",
    "            for label, ind in self.tfidf_vectorizer.vocabulary_.items():\n",
    "                self.inv_tfidf_vectorizer_vocab[ind] = label\n",
    "\n",
    "        else:\n",
    "            return NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "    # transformation\n",
    "    def bow_transform(self, data, type = \"tf\"):\n",
    "        if type == \"tf\":\n",
    "            return self.count_vectorizer.transform(data[\"question_processed\"])\n",
    "        elif type == \"tfidf\":\n",
    "            return self.tfidf_vectorizer.transform(data[\"question_processed\"])\n",
    "        else:\n",
    "            return NotImplementedError\n",
    "\n",
    "\n",
    "    # mapping category column's value to integer\n",
    "    category_map = {\"boolean\": 0, \"resource\": 1, \"literal\": 2}\n",
    "    inv_category_map = {}\n",
    "\n",
    "    for label, ind in category_map.items():\n",
    "        inv_category_map[ind] = label\n",
    "\n",
    "    def category_to_int(self, data):\n",
    "        return data.category.map(lambda x: self.category_map[x])\n",
    "\n",
    "\n",
    "    # mapping type-literal value to integer\n",
    "    literal_map = {\"date\": 0, \"string\": 1, \"number\": 2}\n",
    "    inv_literal_map = {}\n",
    "\n",
    "    for label, ind in literal_map.items():\n",
    "        inv_literal_map[ind] = label\n",
    "\n",
    "    def literal_to_int(self, data):\n",
    "        return data.type.map(lambda x: self.literal_map[x[0]])\n",
    "\n",
    "\n",
    "    # distribute type by ontology class and encode missing if none\n",
    "    def type_to_int(self, data, type_no):\n",
    "        return data.type.map(\n",
    "            lambda x: self.type_maps[f\"type{type_no}\"][x[type_no - 1]] \n",
    "            if len(x) >= type_no \n",
    "            else self.type_maps[f\"type{type_no}\"][\"missing\"]\n",
    "            )\n",
    "\n",
    "\n",
    "    # save output\n",
    "    def save_vectorizers(self):\n",
    "        if self.count_vectorizer != None:\n",
    "            with open(\"count_vectorizer.pkl\", \"wb\") as count_file:\n",
    "                pickle.dump(self.count_vectorizer, count_file)\n",
    "        if self.tfidf_vectorizer != None:\n",
    "            with open(\"tfidf_vectorizer.pkl\", \"wb\") as tfidf_file:\n",
    "                pickle.dump(self.tfidf_vectorizer, tfidf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRRJ_AlIwcCS",
    "outputId": "334c2027-3467-4c37-ad60-18dd1e313271"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "etl = ETL(path_to_type_maps=\"./\", path_to_vectorizers=\"./\")\n",
    "\n",
    "# split dataset\n",
    "df_train, df_val = etl.split_data(train_data)\n",
    "\n",
    "# text normalization\n",
    "df_train = etl.norm_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "_YJAsGNPC9Dv",
    "outputId": "79a326a1-a8d9-47f8-e667-103e1fd7a3dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>question_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23782</th>\n",
       "      <td>29658</td>\n",
       "      <td>What film did zhang yimou direct?</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Film, dbo:Work]</td>\n",
       "      <td>what film did zhang yimou direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18007</th>\n",
       "      <td>22426</td>\n",
       "      <td>who is the governor of hawaii now</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Person, dbo:Politician, dbo:Agent, dbo:Of...</td>\n",
       "      <td>who is the governor of hawaii now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19818</th>\n",
       "      <td>24691</td>\n",
       "      <td>where was rihanna born and raised</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Place, dbo:Location, dbo:Settlement, dbo:...</td>\n",
       "      <td>where wa rihanna born and raised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>12483</td>\n",
       "      <td>Which is the authority for the congress of the...</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Meeting, dbo:SocietalEvent, dbo:Event]</td>\n",
       "      <td>which is the authority for the congress of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23520</th>\n",
       "      <td>29329</td>\n",
       "      <td>in what german city did hermann beckh die</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Place, dbo:Location, dbo:Settlement, dbo:...</td>\n",
       "      <td>in what german city did hermann beckh die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26865</th>\n",
       "      <td>33519</td>\n",
       "      <td>what is a lower classification of bear</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Mammal, dbo:Mammal, dbo:Animal, dbo:Insec...</td>\n",
       "      <td>what is a lower classification of bear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7188</th>\n",
       "      <td>8979</td>\n",
       "      <td>What is the natural abundance of helium-3?</td>\n",
       "      <td>literal</td>\n",
       "      <td>[number]</td>\n",
       "      <td>what is the natural abundance of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34415</th>\n",
       "      <td>42977</td>\n",
       "      <td>who is sanjay khan's child?</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Person, dbo:Agent]</td>\n",
       "      <td>who is sanjay khan child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26937</th>\n",
       "      <td>33609</td>\n",
       "      <td>what type of music does does it look like im h...</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Genre, dbo:TopicalConcept, dbo:MusicGenre]</td>\n",
       "      <td>what type of music doe doe it look like im her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22953</th>\n",
       "      <td>28648</td>\n",
       "      <td>which world conflict did gustav gihr participa...</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Event, dbo:MilitaryConflict, dbo:Military...</td>\n",
       "      <td>which world conflict did gustav gihr participa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29667 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           question  category  \\\n",
       "23782  29658                  What film did zhang yimou direct?  resource   \n",
       "18007  22426                  who is the governor of hawaii now  resource   \n",
       "19818  24691                  where was rihanna born and raised  resource   \n",
       "10011  12483  Which is the authority for the congress of the...  resource   \n",
       "23520  29329          in what german city did hermann beckh die  resource   \n",
       "...      ...                                                ...       ...   \n",
       "26865  33519            what is a lower classification of bear   resource   \n",
       "7188    8979         What is the natural abundance of helium-3?   literal   \n",
       "34415  42977                        who is sanjay khan's child?  resource   \n",
       "26937  33609  what type of music does does it look like im h...  resource   \n",
       "22953  28648  which world conflict did gustav gihr participa...  resource   \n",
       "\n",
       "                                                    type  \\\n",
       "23782                               [dbo:Film, dbo:Work]   \n",
       "18007  [dbo:Person, dbo:Politician, dbo:Agent, dbo:Of...   \n",
       "19818  [dbo:Place, dbo:Location, dbo:Settlement, dbo:...   \n",
       "10011        [dbo:Meeting, dbo:SocietalEvent, dbo:Event]   \n",
       "23520  [dbo:Place, dbo:Location, dbo:Settlement, dbo:...   \n",
       "...                                                  ...   \n",
       "26865  [dbo:Mammal, dbo:Mammal, dbo:Animal, dbo:Insec...   \n",
       "7188                                            [number]   \n",
       "34415                            [dbo:Person, dbo:Agent]   \n",
       "26937    [dbo:Genre, dbo:TopicalConcept, dbo:MusicGenre]   \n",
       "22953  [dbo:Event, dbo:MilitaryConflict, dbo:Military...   \n",
       "\n",
       "                                      question_processed  \n",
       "23782                   what film did zhang yimou direct  \n",
       "18007                  who is the governor of hawaii now  \n",
       "19818                   where wa rihanna born and raised  \n",
       "10011  which is the authority for the congress of the...  \n",
       "23520          in what german city did hermann beckh die  \n",
       "...                                                  ...  \n",
       "26865             what is a lower classification of bear  \n",
       "7188                    what is the natural abundance of  \n",
       "34415                           who is sanjay khan child  \n",
       "26937  what type of music doe doe it look like im her...  \n",
       "22953  which world conflict did gustav gihr participa...  \n",
       "\n",
       "[29667 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "9-eJbPUf5vRp",
    "outputId": "306ca221-bfaf-478f-d851-17e3d84f3941"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22014</th>\n",
       "      <td>27463</td>\n",
       "      <td>What type of object is 3809 amici</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Planet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18208</th>\n",
       "      <td>22675</td>\n",
       "      <td>what college did matt schaub play for</td>\n",
       "      <td>resource</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37635</th>\n",
       "      <td>47013</td>\n",
       "      <td>What country made horses of god</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Place, dbo:Location, dbo:ArchitecturalStr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23306</th>\n",
       "      <td>29074</td>\n",
       "      <td>What company produced the film changeling?</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Company, dbo:Film, dbo:Organisation, dbo:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>2251</td>\n",
       "      <td>The Maurya Empire covered which modern-day cou...</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Person, dbo:Agent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18340</th>\n",
       "      <td>22838</td>\n",
       "      <td>where is mallorca</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Place, dbo:Location, dbo:Sea, dbo:BodyOfW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13342</th>\n",
       "      <td>16578</td>\n",
       "      <td>Count the number of first drivers in all the G...</td>\n",
       "      <td>literal</td>\n",
       "      <td>[number]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13426</th>\n",
       "      <td>16685</td>\n",
       "      <td>Is the individual tax rate in Sweden 25%?</td>\n",
       "      <td>boolean</td>\n",
       "      <td>[boolean]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26658</th>\n",
       "      <td>33265</td>\n",
       "      <td>who wrote a wizard abroad?</td>\n",
       "      <td>resource</td>\n",
       "      <td>[dbo:Person, dbo:Writer, dbo:Agent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>12709</td>\n",
       "      <td>Which is the ARLIMA ID for lexicon?</td>\n",
       "      <td>literal</td>\n",
       "      <td>[string]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7417 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           question  category  \\\n",
       "22014  27463                  What type of object is 3809 amici  resource   \n",
       "18208  22675              what college did matt schaub play for  resource   \n",
       "37635  47013                    What country made horses of god  resource   \n",
       "23306  29074         What company produced the film changeling?  resource   \n",
       "1802    2251  The Maurya Empire covered which modern-day cou...  resource   \n",
       "...      ...                                                ...       ...   \n",
       "18340  22838                                  where is mallorca  resource   \n",
       "13342  16578  Count the number of first drivers in all the G...   literal   \n",
       "13426  16685          Is the individual tax rate in Sweden 25%?   boolean   \n",
       "26658  33265                         who wrote a wizard abroad?  resource   \n",
       "10197  12709                Which is the ARLIMA ID for lexicon?   literal   \n",
       "\n",
       "                                                    type  \n",
       "22014                                       [dbo:Planet]  \n",
       "18208                                                 []  \n",
       "37635  [dbo:Place, dbo:Location, dbo:ArchitecturalStr...  \n",
       "23306  [dbo:Company, dbo:Film, dbo:Organisation, dbo:...  \n",
       "1802                             [dbo:Person, dbo:Agent]  \n",
       "...                                                  ...  \n",
       "18340  [dbo:Place, dbo:Location, dbo:Sea, dbo:BodyOfW...  \n",
       "13342                                           [number]  \n",
       "13426                                          [boolean]  \n",
       "26658                [dbo:Person, dbo:Writer, dbo:Agent]  \n",
       "10197                                           [string]  \n",
       "\n",
       "[7417 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ku3cAUNXuzUG"
   },
   "outputs": [],
   "source": [
    "# vectorization - bag of words model\n",
    "etl.bow_fit(corpus = df_train, type = \"tf\")\n",
    "etl.save_vectorizers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpGAtqqku-Mb"
   },
   "source": [
    "## 2. Category Prediction Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hNrKgk6Cu9b8"
   },
   "outputs": [],
   "source": [
    "# set category prediction dataset\n",
    "X_train_category = etl.bow_transform(df_train)\n",
    "y_train_category = etl.category_to_int(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-2QymUbxPNo",
    "outputId": "fe5249b6-846b-4d2c-d0c0-859163794121"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 177 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  2.9min finished\n"
     ]
    }
   ],
   "source": [
    "# model for category classification\n",
    "clf_category = LogisticRegression(\n",
    "    random_state=seed, penalty = 'elasticnet', solver = 'saga',\n",
    "    l1_ratio = 0.2, n_jobs = -1, verbose = 2)\\\n",
    "    .fit(X_train_category, y_train_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhcXhB1491gk",
    "outputId": "0d185ad1-735c-4cb1-9879-b7385c48fbac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9858765631846833"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_category.score(X_train_category, y_train_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6t3q77QvuOE"
   },
   "source": [
    "## 3-1. Type Prediction Task - Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vi_yxC3C5nrx",
    "outputId": "cabb7276-e848-465c-9db8-f3a35d2cd3c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.4s finished\n"
     ]
    }
   ],
   "source": [
    "# model for literal classification\n",
    "# get which rows are for literal only  \n",
    "train_literal_rows = (df_train[\"category\"] == \"literal\").values\n",
    "y_train_literal = etl.literal_to_int(df_train[train_literal_rows])\n",
    "\n",
    "clf_literal = LogisticRegression(\n",
    "    random_state=seed, penalty = 'elasticnet', solver = 'saga',\n",
    "    l1_ratio = 0.5, n_jobs = -1, verbose = 2\n",
    "    )\\\n",
    "    .fit(X_train_category[train_literal_rows, :], y_train_literal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ihsyVY143UPg",
    "outputId": "1693fe4e-a6e4-40ce-9ebd-99741179d6a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972822910578609"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_literal.score(X_train_category[train_literal_rows], y_train_literal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hr-4DSgGGYoF"
   },
   "source": [
    "## 3-2. Type Prediction Task - Resource\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bLD1-vEVYWj"
   },
   "source": [
    "***Identify types of resources in the train data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SZe_y3EeIYvz"
   },
   "outputs": [],
   "source": [
    "levels = range(1, 6)\n",
    "\n",
    "for l in levels:\n",
    "    ind = 0\n",
    "    temp_dict = {}\n",
    "    temp_df = df_train[df_train[\"category\"] == \"resource\"][\"type\"].map(lambda x: x[l-1] if len(x) >= l else \"missing\").to_frame(f\"type{l}\")\n",
    "    for ontology in temp_df[f\"type{l}\"]:\n",
    "        if ontology not in temp_dict:\n",
    "            temp_dict[ontology] = ind \n",
    "            ind += 1\n",
    "    with open(f\"type{l}_map.json\", \"w\") as outfile:\n",
    "        temp_json_obj = json.dump(temp_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PorG_IvOK4_N",
    "outputId": "67de44b2-675a-4670-feea-bbfe6cbb6d60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.26369687\n",
      "Iteration 2, loss = 1.07734467\n",
      "Iteration 3, loss = 0.65226379\n",
      "Iteration 4, loss = 0.40591306\n",
      "Iteration 5, loss = 0.27326443\n",
      "Iteration 6, loss = 0.20030961\n",
      "Iteration 7, loss = 0.16221546\n",
      "Iteration 8, loss = 0.14199448\n",
      "Iteration 9, loss = 0.12467818\n",
      "Iteration 10, loss = 0.11484542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.08586444\n",
      "Iteration 2, loss = 1.02620969\n",
      "Iteration 3, loss = 0.63665499\n",
      "Iteration 4, loss = 0.41644748\n",
      "Iteration 5, loss = 0.29253741\n",
      "Iteration 6, loss = 0.23276518\n",
      "Iteration 7, loss = 0.19529822\n",
      "Iteration 8, loss = 0.17462429\n",
      "Iteration 9, loss = 0.16215116\n",
      "Iteration 10, loss = 0.14617416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.81027879\n",
      "Iteration 2, loss = 0.95233640\n",
      "Iteration 3, loss = 0.64082126\n",
      "Iteration 4, loss = 0.43626876\n",
      "Iteration 5, loss = 0.32557114\n",
      "Iteration 6, loss = 0.26302589\n",
      "Iteration 7, loss = 0.21794966\n",
      "Iteration 8, loss = 0.19488477\n",
      "Iteration 9, loss = 0.17331330\n",
      "Iteration 10, loss = 0.16427897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.50571014\n",
      "Iteration 2, loss = 0.82552376\n",
      "Iteration 3, loss = 0.56220561\n",
      "Iteration 4, loss = 0.39355751\n",
      "Iteration 5, loss = 0.29124314\n",
      "Iteration 6, loss = 0.23135278\n",
      "Iteration 7, loss = 0.19357294\n",
      "Iteration 8, loss = 0.17457585\n",
      "Iteration 9, loss = 0.15960374\n",
      "Iteration 10, loss = 0.14643053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.98857775\n",
      "Iteration 2, loss = 0.53605357\n",
      "Iteration 3, loss = 0.38768069\n",
      "Iteration 4, loss = 0.27935119\n",
      "Iteration 5, loss = 0.21317966\n",
      "Iteration 6, loss = 0.17591220\n",
      "Iteration 7, loss = 0.15072062\n",
      "Iteration 8, loss = 0.13822981\n",
      "Iteration 9, loss = 0.12344304\n",
      "Iteration 10, loss = 0.11715094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "resource_models = []\n",
    "\n",
    "for l in range(1, 6):\n",
    "    # model for literal classification\n",
    "    # get which rows are for literal only  \n",
    "    train_resource_rows = (df_train[\"category\"] == \"resource\").values\n",
    "    y_train_type = etl.type_to_int(df_train[train_resource_rows], type_no=l)\n",
    "\n",
    "    clf_type = MLPClassifier(\n",
    "      random_state=seed, max_iter=10, hidden_layer_sizes=(1000, 500, 300)\n",
    "      , verbose = 2).\\\n",
    "    fit(X_train_category[train_resource_rows], y_train_type)\n",
    "\n",
    "    resource_models.append(clf_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "8fxgGgeOMM9W"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.971252399036302"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_type.score(X_train_category[train_resource_rows], y_train_type) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwcZ38iu_YYH"
   },
   "source": [
    "## 4. Save models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "EJnfBXgkfyUr"
   },
   "outputs": [],
   "source": [
    "with open(\"category_model.pkl\", \"wb\") as mdl_file:\n",
    "    pickle.dump(clf_category, mdl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "X_QaOf94RtQs"
   },
   "outputs": [],
   "source": [
    "with open(\"literal_model.pkl\", \"wb\") as mdl_file:\n",
    "    pickle.dump(clf_literal, mdl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ASFCv0nkaphR"
   },
   "outputs": [],
   "source": [
    "for l in range(1,6):\n",
    "    with open(f\"resource_level_{l}_model.pkl\", \"wb\") as mdl_file:\n",
    "        pickle.dump(resource_models[l-1], mdl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pol2B42Cw2ck"
   },
   "source": [
    "## 5. Results & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "orIFdQaDN9ba"
   },
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self, etl_inst, cat_model, lit_model, res_models):\n",
    "        self.etl_inst = etl_inst\n",
    "        self.cat_model = cat_model\n",
    "        self.lit_model = lit_model\n",
    "        self.res_models = res_models\n",
    "  \n",
    "    # X is a df\n",
    "    def get_predictions(self, X, bow_type = \"tf\"):\n",
    "\n",
    "        X = X.copy()\n",
    "\n",
    "        X.reset_index(inplace = True, drop = True)\n",
    "\n",
    "        X_norm = self.etl_inst.norm_data(X)\n",
    "        X_vec = self.etl_inst.bow_transform(X_norm, type = bow_type)\n",
    "\n",
    "        bool_int = self.etl_inst.category_map[\"boolean\"]\n",
    "        literal_int = self.etl_inst.category_map[\"literal\"]\n",
    "        resource_int = self.etl_inst.category_map[\"resource\"]\n",
    "\n",
    "        cat_pred = self.cat_model.predict(X_vec)\n",
    "\n",
    "        ind_bool = cat_pred == bool_int\n",
    "        ind_literal = cat_pred == literal_int\n",
    "        ind_resource = cat_pred == resource_int\n",
    "\n",
    "        if len(ind_bool) > 0:\n",
    "            X.loc[ind_bool, \"cat_prediction\"] = \"boolean\"\n",
    "            X.loc[ind_bool, \"type_prediction\"] = pd.Series(\n",
    "              cat_pred[ind_bool], name = \"type_prediction\")\\\n",
    "              .map(lambda x: [\"boolean\"]).values\n",
    "\n",
    "        if len(ind_literal) > 0:\n",
    "            X.loc[ind_literal, \"cat_prediction\"] = \"literal\"\n",
    "            literal_pred = self.lit_model.predict(X_vec[ind_literal])\n",
    "            X.loc[ind_literal, \"type_prediction\"] = pd.Series(\n",
    "              literal_pred, name = \"type_prediction\")\\\n",
    "              .map(lambda x: [self.etl_inst.inv_literal_map[x]]).values\n",
    "\n",
    "        if len(ind_resource) > 0:\n",
    "            resource_preds = []\n",
    "            for ind, type_model in enumerate(self.res_models):\n",
    "                resource_preds.append(\n",
    "                pd.Series(\n",
    "                    type_model.predict(X_vec[ind_resource]), name = f\"type_{ind}\").\\\n",
    "                    map(lambda x: self.etl_inst.inv_type_maps[f\"type{ind+1}\"][x])\n",
    "                    )\n",
    "            resource_preds = pd.Series(pd.concat(resource_preds, axis = 1).values.tolist(), name = \"type_prediction\")\n",
    "            X.loc[ind_resource, \"type_prediction\"] = resource_preds.values\n",
    "            X.loc[ind_resource, \"cat_prediction\"] = \"resource\"\n",
    "      \n",
    "        return X\n",
    "\n",
    "    def output_predictions(self):\n",
    "        return NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "D6BLutJ8jA-M"
   },
   "outputs": [],
   "source": [
    "me = ModelEvaluation(etl, clf_category, clf_literal, resource_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "5BNZ9bpmyJIM"
   },
   "outputs": [],
   "source": [
    "out_val = me.get_predictions(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ZsH1PomB-_KA"
   },
   "outputs": [],
   "source": [
    "output_format_val = out_val.loc[:, [\"id\", \"cat_prediction\", \"type_prediction\"]].to_dict(orient = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "T3jtos9B_ci6"
   },
   "outputs": [],
   "source": [
    "output_format_val = [pred for ind, pred in output_format_val.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "30LEgHJQ5R0A"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 27463,\n",
       "  'cat_prediction': 'resource',\n",
       "  'type_prediction': ['dbo:Planet',\n",
       "   'missing',\n",
       "   'missing',\n",
       "   'missing',\n",
       "   'missing']},\n",
       " {'id': 22675,\n",
       "  'cat_prediction': 'resource',\n",
       "  'type_prediction': ['dbo:EducationalInstitution',\n",
       "   'dbo:Organisation',\n",
       "   'dbo:Agent',\n",
       "   'dbo:University',\n",
       "   'missing']},\n",
       " {'id': 47013,\n",
       "  'cat_prediction': 'resource',\n",
       "  'type_prediction': ['dbo:Organisation',\n",
       "   'dbo:Country',\n",
       "   'dbo:Place',\n",
       "   'dbo:Place',\n",
       "   'dbo:Location']},\n",
       " {'id': 29074,\n",
       "  'cat_prediction': 'resource',\n",
       "  'type_prediction': ['dbo:Company',\n",
       "   'dbo:Organisation',\n",
       "   'dbo:Agent',\n",
       "   'missing',\n",
       "   'missing']},\n",
       " {'id': 2251,\n",
       "  'cat_prediction': 'resource',\n",
       "  'type_prediction': ['dbo:Country',\n",
       "   'dbo:PopulatedPlace',\n",
       "   'dbo:Place',\n",
       "   'dbo:Place',\n",
       "   'missing']}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_format_val[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9raG_KIyB1x"
   },
   "source": [
    "***Write output to file***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "zPusetmQx_T7"
   },
   "outputs": [],
   "source": [
    "with open('system_output.json', 'w') as outfile:\n",
    "    json.dump(output_format_val, outfile)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SMART2021_AT Prediction Task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
