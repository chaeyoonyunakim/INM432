{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIu7yYEzZaF2J5I0xWx2kM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaeyoonyunakim/NLP-IR-QA/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KLY3vxp15Xh",
        "outputId": "69d862d2-c6d2-4e8c-f61b-f1d54e35c8f8"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUXi4rCI2Qzb",
        "outputId": "39c38ce1-5478-4d13-8d53-b414720a1709"
      },
      "source": [
        "%ls -l \"/content/drive/My Drive/2021_INM363_SMART/smarttask_dbpedia_train.json\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw------- 1 root root 3601280 Feb 23  2021 '/content/drive/My Drive/2021_INM363_SMART/smarttask_dbpedia_train.json'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THji5Cj_2rMB"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import std"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyG2VFkZ2w94"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeVDlbiE2ypH",
        "outputId": "971099b3-7ff1-47d6-a491-5cefc803b4ef"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "#set(stopwords.words('english'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7bhgDWl9aUg",
        "outputId": "f0c209b1-dbc1-44ab-fc13-13bc17c63c88"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re7UB28r2z-P"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwTe9wMf3MpC"
      },
      "source": [
        "## Tabular representation of the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "N1GxpONV3AD5",
        "outputId": "721c575c-72d0-41ae-9a31-2d2d9eb72a60"
      },
      "source": [
        "df = pd.read_json('/content/drive/My Drive/2021_INM363_SMART/smarttask_dbpedia_train.json')\n",
        "df.head(3)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>category</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dbpedia_1177</td>\n",
              "      <td>Was Jacqueline Kennedy Onassis a follower of M...</td>\n",
              "      <td>boolean</td>\n",
              "      <td>[boolean]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dbpedia_14427</td>\n",
              "      <td>What is the name of the opera based on Twelfth...</td>\n",
              "      <td>resource</td>\n",
              "      <td>[dbo:Opera, dbo:MusicalWork, dbo:Work]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dbpedia_16615</td>\n",
              "      <td>When did Lena Horne receive the Grammy Award f...</td>\n",
              "      <td>literal</td>\n",
              "      <td>[date]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              id  ...                                    type\n",
              "0   dbpedia_1177  ...                               [boolean]\n",
              "1  dbpedia_14427  ...  [dbo:Opera, dbo:MusicalWork, dbo:Work]\n",
              "2  dbpedia_16615  ...                                  [date]\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgeZu4bD3JXL",
        "outputId": "9c4094c7-6b0c-40a3-c565-cb67e7189072"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17571, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJCtM3Ip3MEq",
        "outputId": "a5c56723-479a-4eaf-c58e-f5f8f1d9f01d"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id           0\n",
              "question    43\n",
              "category     0\n",
              "type         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2MxRjfm3St2",
        "outputId": "d1580044-3eaf-4205-b65a-83af808f4c99"
      },
      "source": [
        "df.dropna(subset=['id', 'question'], inplace=True)\n",
        "df.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17528, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFPtKOu0hU8R"
      },
      "source": [
        "text = df.question.values\n",
        "#testdata = text.tolist()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD4T9qTH3din"
      },
      "source": [
        "## 1. Preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-YLMZeAhBkl"
      },
      "source": [
        "# clean the corpus\n",
        "sentences = []\n",
        "vocab = []\n",
        "tokens = []\n",
        "\n",
        "for sent in text:\n",
        "    x = word_tokenize(sent)\n",
        "    sentence = [w.lower() for w in x if w.isalpha()]\n",
        "    sentences.append(sentence)\n",
        " \n",
        "    for word in sentence:\n",
        "        if word not in vocab:\n",
        "            vocab.append(word)\n",
        "            \n",
        "for word in vocab:\n",
        "    if word not in stopwords.words():\n",
        "        tokens.append(word)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG3vGIJ1gOdO"
      },
      "source": [
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "ps = PorterStemmer()\n",
        "\n",
        "def normalize_word(w):\n",
        "   word1 = wordnet_lemmatizer.lemmatize(w, pos = \"n\")\n",
        "   word2 = wordnet_lemmatizer.lemmatize(word1, pos = \"v\")\n",
        "   word3 = wordnet_lemmatizer.lemmatize(word2, pos = (\"a\"))\n",
        "   word = ps.stem(word3)\n",
        "   return word\n",
        "\n",
        "\n",
        "## Define the Bag of Words model function\n",
        "def create_bow(word_list):\n",
        "  ind = 0 \n",
        "  bow = {}\n",
        "  for w in word_list:\n",
        "    _w = normalize_word(w)\n",
        "    if _w not in bow:\n",
        "      bow[_w] = ind \n",
        "      ind += 1 \n",
        "  return bow\n",
        "bow = create_bow(tokens)\n",
        "\n",
        "\n",
        "## Assign an index to the word\n",
        "label_map = {\"boolean\": 1, \"resource\":2, \"literal\":3}\n",
        "\n",
        "def map_to_vec(df, bow):\n",
        "  # add 1 for now just for the category\n",
        "  # requires additional cols for literals and sub resources for later\n",
        "  ncols = len(bow) + 1 \n",
        "  data = np.zeros(shape = (df.shape[0], ncols ))\n",
        "  \n",
        "  for i in range(df.shape[0]):\n",
        "    # set the label\n",
        "    data[i, -1] = label_map[df.iloc[i, 2]]\n",
        "    # parse the sentence\n",
        "    que = df.iloc[i, 1]\n",
        "    for w in word_tokenize(que):\n",
        "      w = w.lower()\n",
        "      if w.isalpha():\n",
        "        # normalize word\n",
        "        w_norm = normalize_word(w)\n",
        "        if w_norm in bow:\n",
        "          # print(f\"({i}, {w_norm})\")\n",
        "          data[i, bow[w_norm]] += 1 \n",
        "  return data\n",
        "\n",
        "data = map_to_vec(df, bow)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMOBJXdVjZDC",
        "outputId": "4dd8fd22-a5dd-487f-9bcc-4c0b8ba1cac0"
      },
      "source": [
        "data"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 2.],\n",
              "       [0., 0., 0., ..., 0., 0., 3.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 2.],\n",
              "       [0., 0., 0., ..., 0., 1., 2.],\n",
              "       [0., 0., 0., ..., 0., 0., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3j94wG9IV8T"
      },
      "source": [
        "## 2. Train a classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGPB48U6klwU"
      },
      "source": [
        "X = data[:,:-1]\n",
        "y = data[:,-1]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROSj29JsjoE7"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1oM0vw0JetC"
      },
      "source": [
        "***Build a Classifier***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "872YmRSHJomK"
      },
      "source": [
        "# define the multinomial logistic regression model\n",
        "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "# define the model evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "# evaluate the model and collect the scores\n",
        "n_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC1_YaD9e0tS",
        "outputId": "88b08dcb-d7a4-469f-b61e-e627650d461d"
      },
      "source": [
        "# report the model performance\n",
        "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Accuracy: 0.880 (0.008)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}